{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "febf802b-1568-4b02-950d-c62d767a85b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://www.kaggle.com/code/hojjatk/read-mnist-dataset\n",
    "# This is a sample Notebook to demonstrate how to read \"MNIST Dataset\"\n",
    "#\n",
    "import numpy as np # linear algebra\n",
    "import struct\n",
    "from array import array\n",
    "from os.path  import join\n",
    "\n",
    "#\n",
    "# MNIST Data Loader Class\n",
    "#\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = 'train-images.idx3-ubyte'\n",
    "        self.training_labels_filepath = 'train-labels.idx1-ubyte'\n",
    "        self.test_images_filepath = 't10k-images.idx3-ubyte'\n",
    "        self.test_labels_filepath = 't10k-labels.idx1-ubyte'\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd01f4e1-46a7-425e-a259-c9c4057ae3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://www.kaggle.com/code/hojjatk/read-mnist-dataset\n",
    "# This is a sample Notebook to demonstrate how to read \"MNIST Dataset\"\n",
    "#\n",
    "import numpy as np # linear algebra\n",
    "import struct\n",
    "from array import array\n",
    "from os.path  import join\n",
    "\n",
    "#\n",
    "# MNIST Data Loader Class\n",
    "#\n",
    "class MnistDataloader(object):\n",
    "    def __init__(self, training_images_filepath,training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = 'train-images.idx3-ubyte'\n",
    "        self.training_labels_filepath = 'train-labels.idx1-ubyte'\n",
    "        self.test_images_filepath = 't10k-images.idx3-ubyte'\n",
    "        self.test_labels_filepath = 't10k-labels.idx1-ubyte'\n",
    "    \n",
    "    def read_images_labels(self, images_filepath, labels_filepath):        \n",
    "        labels = []\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = array(\"B\", file.read())        \n",
    "        \n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = array(\"B\", file.read())        \n",
    "        images = []\n",
    "        for i in range(size):\n",
    "            images.append([0] * rows * cols)\n",
    "        for i in range(size):\n",
    "            img = np.array(image_data[i * rows * cols:(i + 1) * rows * cols])\n",
    "            img = img.reshape(28, 28)\n",
    "            images[i][:] = img            \n",
    "        \n",
    "        return images, labels\n",
    "            \n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train),(x_test, y_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93233ffc-81e1-42a4-b39a-d13f53650485",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train-labels.idx1-ubyte'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Load MINST dataset\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     17\u001b[0m mnist_dataloader \u001b[38;5;241m=\u001b[39m MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n\u001b[1;32m---> 18\u001b[0m (x_train, y_train), (x_test, y_test) \u001b[38;5;241m=\u001b[39m mnist_dataloader\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[0;32m     20\u001b[0m X_train \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     21\u001b[0m X_test \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[1;32mIn[2], line 44\u001b[0m, in \u001b[0;36mMnistDataloader.load_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 44\u001b[0m     x_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_images_labels(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_images_filepath, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_labels_filepath)\n\u001b[0;32m     45\u001b[0m     x_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_images_labels(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_images_filepath, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_labels_filepath)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (x_train, y_train),(x_test, y_test)\n",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m, in \u001b[0;36mMnistDataloader.read_images_labels\u001b[1;34m(self, images_filepath, labels_filepath)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_images_labels\u001b[39m(\u001b[38;5;28mself\u001b[39m, images_filepath, labels_filepath):        \n\u001b[0;32m     21\u001b[0m     labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(labels_filepath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     23\u001b[0m         magic, size \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>II\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2049\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train-labels.idx1-ubyte'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "# Set file paths based on added MNIST Datasets\n",
    "#\n",
    "input_path = '../input'\n",
    "training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "\n",
    "#\n",
    "# Load MINST dataset\n",
    "#\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    r = random.randint(0, 60000)\n",
    "    X_train.append(x_train[r])\n",
    "    Y_train.append(y_train[r])\n",
    "\n",
    "for i in range(0, 500):\n",
    "    r = random.randint(1, 10000)\n",
    "    X_test.append(x_test[r])\n",
    "    Y_test.append(y_test[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff50ee63-79fa-4174-bafa-639cdc130ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf0a006-7644-4f75-b30a-4e7bafe89480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Train:\", np.array(X_train).shape, np.array(Y_train).shape)\n",
    "print(\"Test:\", np.array(X_test).shape, np.array(Y_test).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57893b4-9182-4927-99b3-4e363e4bbf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En este ejemplo agregamos una cuarta dimension, que sería la cantidad de canales de cada imagen.\n",
    "# Vamos a usar la imagen en forma de matriz como entrada en el modelo.\n",
    "\n",
    "X_train =  np.array(X_train).reshape((10000, 28, 28, 1))\n",
    "X_test = np.array(X_test).reshape((500, 28, 28, 1))\n",
    "\n",
    "# Normalizacion\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "\n",
    "# One Hot Encoding\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "\n",
    "print(\"Train:\", X_train.shape, Y_train.shape)\n",
    "print(\"Test:\", X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7923f64f-8c95-46f2-a8c4-58bded36ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(Y_train[0])\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa123120-4366-43ae-b311-44805d28a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el modelo LeNet5\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Capa de Entrada (Convolucion)\n",
    "model.add(Conv2D(filters = 6, \n",
    "                 kernel_size = (5, 5),\n",
    "                 #strides=(1, 1),\n",
    "                 activation = \"relu\", \n",
    "                 input_shape = (28, 28, 1))) # La capa de convolución siempre lleva relu\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Convolucion\n",
    "model.add(Conv2D(filters = 16, \n",
    "                 kernel_size = (5, 5), \n",
    "                 activation = \"relu\"))\n",
    "\n",
    "# Pooling\n",
    "model.add(AveragePooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Flatten (Las aplanamos para seguir con la red neuronal)\n",
    "model.add(Flatten())\n",
    "\n",
    "# Capas Ocultas\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dense(128, activation = \"relu\"))\n",
    "\n",
    "# Capa de Salida (Si es un problema de clasificación multiple siempre debe terminar con \"softmax\")\n",
    "model.add(Dense(num_classes, activation = \"softmax\"))\n",
    "\n",
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9521a80d-65b7-4e2a-8819-ee70f9fd1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilamos el modelo\n",
    "model.compile(loss      = \"categorical_crossentropy\",\n",
    "              optimizer = \"adam\",\n",
    "              metrics   = [\"AUC\"])\n",
    "\n",
    "# Entrenamos el modelo\n",
    "history = model.fit(x = X_train, y = Y_train,\n",
    "          validation_data = (X_test, Y_test),\n",
    "          epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f42186a-fc09-4ced-9c6f-fed23e4bf98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_auc = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print(\"Test accuracy:\", test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067737ec-06a2-4a1d-aa0f-a86ffadb79a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "y_hat = model.predict(X_test)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33083e-f3c4-42b1-aa7a-7026612ed83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revertimos One-Hot Encoding\n",
    "\n",
    "y_hat = [np.argmax(i) for i in y_hat]\n",
    "Y_test = [np.argmax(i) for i in Y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba23fb-a1fa-47cf-9bf9-6524141a1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac94aa38-b798-4952-ad1c-dd8ac761509d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf5165f-1307-4616-807a-f56f9ce469bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2fcd50-32ed-40d2-98e9-2a310f0c5122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6ad8bd-af9e-471f-9287-f3fb4d288ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
